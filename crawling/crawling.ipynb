{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from selenium import webdriver\r\n",
    "import pandas as pd\r\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def get_date_df(filename='flood.xlsx'):\r\n",
    "    raw_data = pd.read_excel(filename, skiprows=2, header=None, usecols=[0, 1, 2, 3])\r\n",
    "\r\n",
    "    raw_data.columns = ['flood_id', 'year', 'month', 'day']\r\n",
    "    raw_data.set_index(['flood_id'], inplace=True)\r\n",
    "\r\n",
    "    date_df = pd.to_datetime(raw_data).dt.strftime('%Y-%m-%d') \\\r\n",
    "                .groupby('flood_id').agg(['first', 'last'])\r\n",
    "    \r\n",
    "    return date_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "FLOOD_DATE = get_date_df('../flood.xlsx')\r\n",
    "FLOOD_DATE.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               first        last\n",
       "flood_id                        \n",
       "1         2006-07-10  2006-07-19\n",
       "2         2006-07-25  2006-07-30\n",
       "3         2007-08-03  2007-08-07\n",
       "4         2007-09-14  2007-09-15\n",
       "5         2008-07-23  2008-07-27"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flood_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-07-10</td>\n",
       "      <td>2006-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-07-25</td>\n",
       "      <td>2006-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-08-03</td>\n",
       "      <td>2007-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-09-14</td>\n",
       "      <td>2007-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008-07-23</td>\n",
       "      <td>2008-07-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "driver = webdriver.Chrome('./chromedriver.exe')\r\n",
    "# driver = webdriver.Firefox('./geckodriver.exe')\r\n",
    "driver.get('https://www.water.or.kr/realtime/sub01/sub01/dam/hydr.do?seq=1408&p_group_seq=1407&menu_mode=2')\r\n",
    "driver.implicitly_wait(5)\r\n",
    "driver.refresh()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 다목적댐 제외한 댐 이름 리스트에 저장하기\r\n",
    "dam_ids = []\r\n",
    "\r\n",
    "dam_box = driver.find_element_by_xpath('//*[@id=\"sub_container\"]/div[2]/div[2]/div[3]/div/div[1]/div[2]') \\\r\n",
    "                .find_elements_by_tag_name('ul')\r\n",
    "                \r\n",
    "del dam_box[2]\r\n",
    "\r\n",
    "for dam_list in dam_box:\r\n",
    "    dams = dam_list.find_elements_by_tag_name('li')\r\n",
    "    del dams[0]\r\n",
    "    \r\n",
    "    for dam in dams:\r\n",
    "        dam_ids.append(dam.get_attribute('id'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(dam_ids)\r\n",
    "len(dam_ids)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['1012110', '1006110', '2001110', '2002110', '2015110', '2018110', '2021110', '2008101', '2010101', '2004101', '2002111', '2012101', '1003110', '3008110', '3203110', '3001110', '4001110', '4007110', '4104610', '3303110', '5101110', '1001210', '1302210', '2012210', '2101210', '2403201', '2021210', '2201231', '2201220', '2201230', '2301210', '2503210', '2503220', '4105210', '5002201', '1009710', '1021701', '1022701', '1007701', '5001701', '5003701', '2022510']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from selenium.webdriver.support.ui import Select\r\n",
    "\r\n",
    "period_select = Select(driver.find_element_by_xpath('//*[@id=\"formtab1\"]/fieldset/div/div/div[2]/span/select[1]'))\r\n",
    "period_select.select_by_visible_text('시간별')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "dam_select = Select(driver.find_element_by_xpath('//*[@id=\"formtab1\"]/fieldset/div/div/div[2]/span/select[2]'))\r\n",
    "\r\n",
    "first_date = driver.find_element_by_xpath('//*[@id=\"startDate1\"]')\r\n",
    "last_date = driver.find_element_by_xpath('//*[@id=\"endDate1\"]')\r\n",
    "\r\n",
    "search_btn = driver.find_element_by_xpath('//*[@id=\"formtab1\"]/fieldset/div/a')\r\n",
    "\r\n",
    "table = driver.find_element_by_xpath('//*[@id=\"grid\"]/div/div[1]/div[2]/div[2]/div/div[1]/table')\r\n",
    "tbody = table.find_element_by_tag_name('tbody')\r\n",
    "\r\n",
    "driver.implicitly_wait(1)\r\n",
    "\r\n",
    "LAST_FLOOD = 26\r\n",
    "\r\n",
    "writer = pd.ExcelWriter('other_dams.xlsx', engine='xlsxwriter')\r\n",
    "\r\n",
    "\r\n",
    "# 댐마다\r\n",
    "for dam_id in dam_ids[:]:\r\n",
    "    dam_select.select_by_value(dam_id)\r\n",
    "    dam_name = dam_select.first_selected_option.text\r\n",
    "    \r\n",
    "    dam_df_list = []\r\n",
    "    \r\n",
    "    # 홍수사상별\r\n",
    "    for flood_id in range(1, LAST_FLOOD+1):\r\n",
    "        first_date.clear()\r\n",
    "        first_date.send_keys(FLOOD_DATE.at[flood_id, 'first'])\r\n",
    "        last_date.clear()\r\n",
    "        last_date.send_keys(FLOOD_DATE.at[flood_id, 'last'])\r\n",
    "        \r\n",
    "        search_btn.click()\r\n",
    "        time.sleep(1)\r\n",
    "                \r\n",
    "        if not tbody.find_elements_by_xpath(\".//*\"):\r\n",
    "            break\r\n",
    "        \r\n",
    "        driver.find_element_by_class_name('tui-last').click()\r\n",
    "        last_page = driver.find_element_by_css_selector('strong.tui-page-btn.tui-is-selected.tui-last-child').text\r\n",
    "        last_page = int(last_page)\r\n",
    "        driver.implicitly_wait(1.5)\r\n",
    "\r\n",
    "\r\n",
    "        flood_df_list = []\r\n",
    "        \r\n",
    "        driver.find_element_by_class_name('tui-first').click()\r\n",
    "        flood_df_list.append(pd.read_html(table.get_attribute(\"outerHTML\"))[0])\r\n",
    "        driver.implicitly_wait(1.5)\r\n",
    "        \r\n",
    "        # 출력 페이지별\r\n",
    "        for page in range(2, last_page+1):\r\n",
    "            driver.find_element_by_class_name('tui-next').click()\r\n",
    "            flood_df_list.append(pd.read_html(table.get_attribute(\"outerHTML\"))[0])\r\n",
    "            driver.implicitly_wait(1.5)\r\n",
    "        \r\n",
    "        flood_df = pd.concat(flood_df_list)\r\n",
    "        flood_df.insert(0, 'flood_id', flood_id)\r\n",
    "        flood_df = flood_df[::-1]\r\n",
    "        dam_df_list.append(flood_df)\r\n",
    "        \r\n",
    "        print(flood_id, end=' ')\r\n",
    "        \r\n",
    "    \r\n",
    "    if dam_df_list:\r\n",
    "        dam_df = pd.concat(dam_df_list)#.reset_index(drop=True)\r\n",
    "        dam_df.columns = ['flood_id', 'period', 'waterlevel', 'reservoir', 'storage_rate', 'rainfall', 'inflow', 'discharge']\r\n",
    "        \r\n",
    "        dam_df.to_excel(writer, sheet_name=dam_name, index=False)\r\n",
    "        print(dam_name, '완료')\r\n",
    "    \r\n",
    "writer.save()\r\n",
    "writer.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 운문댐 완료\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\qaws1\\anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py:336: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> 2010-09-18 17시 자료가 없는 '사연댐'은 사후적으로 제거함"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# 브라우저 닫기\r\n",
    "driver.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5a713242f0e871a0d57880ff72c0594a2d4faa5f69c770498a9899086694f7ed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}